{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import itertools\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'lfw_modified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                     (0.5, 0.5, 0.5))\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, dir_path, transform):\n",
    "        self.images_dict = {}\n",
    "        self.id2image = {}\n",
    "        self.labels = None\n",
    "        self.dir_path = dir_path\n",
    "        self.transform = transform\n",
    "        self.load_images()\n",
    "    \n",
    "    def load_images(self):\n",
    "        # returns labels/names list\n",
    "        self.labels = os.listdir(self.dir_path)\n",
    "        for label in self.labels:\n",
    "            path = os.path.join(self.dir_path, label)\n",
    "            images = os.listdir(path)\n",
    "            self.images_dict[label] = images\n",
    "            for image_id in images:\n",
    "                img_path = os.path.join(path, image_id)\n",
    "                self.id2image[image_id] = self.transform(Image.open(img_path))\n",
    "    \n",
    "    def gen_data(self):\n",
    "        labels = []\n",
    "        image_ids = []\n",
    "        for label, images in self.images_dict.items():\n",
    "            num_images = len(images)\n",
    "            labels.extend([label] * num_images)\n",
    "            image_ids.extend(images)\n",
    "        return image_ids, labels\n",
    "        \n",
    "    def get_image(self, image_id):\n",
    "        return self.id2image[image_id]\n",
    "\n",
    "def shuffle_data(data, seed = 0):\n",
    "    image_ids, labels = data\n",
    "    shuffled_image_ids = []\n",
    "    shuffled_labels = []\n",
    "    num_images = len(image_ids)\n",
    "    torch.manual_seed(seed)\n",
    "    perm = list(torch.randperm(num_images))\n",
    "    for i in range(num_images):\n",
    "        shuffled_image_ids.append(image_ids[perm[i]])\n",
    "        shuffled_labels.append(labels[perm[i]])\n",
    "    return shuffled_image_ids, shuffled_labels\n",
    "\n",
    "def make_minibatches(data, minibatch_size = 16,  seed = 0):\n",
    "    X, Y = data\n",
    "    m = len(X)\n",
    "    minibatches = []\n",
    "\n",
    "    shuffled_X, shuffled_Y = shuffle_data(data, seed = seed)\n",
    "\n",
    "    num_complete_minibatches = math.floor(m/minibatch_size)\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        minibatch_X = shuffled_X[k * minibatch_size : k * minibatch_size + minibatch_size]\n",
    "        minibatch_Y = shuffled_Y[k * minibatch_size : k * minibatch_size + minibatch_size]\n",
    "        minibatches.append((minibatch_X, minibatch_Y))\n",
    "\n",
    "    rem_size = m - num_complete_minibatches * minibatch_size\n",
    "    if m % minibatch_size != 0:\n",
    "        minibatch_X = shuffled_X[num_complete_minibatches * minibatch_size : m]\n",
    "        minibatch_Y = shuffled_Y[num_complete_minibatches * minibatch_size : m]\n",
    "        minibatches.append((minibatch_X, minibatch_Y))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def batch2embeddings(minibatch_X, cnn, dataloader, gpu_device):\n",
    "    minibatch_size = len(minibatch_X)\n",
    "    images_tensor = torch.zeros(minibatch_size, 3, 224, 224)\n",
    "    id2embeds = {}\n",
    "    for i in range(minibatch_size):\n",
    "        x = minibatch_X[i]\n",
    "        x_image = dataloader.get_image(x)\n",
    "        images_tensor[i, :, :, :] = x_image\n",
    "    images_tensor = Variable(images_tensor)\n",
    "    if torch.cuda.is_available():\n",
    "        with torch.cuda.device(gpu_device):\n",
    "            images_tensor = images_tensor.cuda()\n",
    "    embeds = cnn(images_tensor)\n",
    "    for i in range(minibatch_size):\n",
    "        x = minibatch_X[i]\n",
    "        id2embeds[x] = embeds[i, :]\n",
    "    return id2embeds\n",
    "\n",
    "\n",
    "def gen_triplets(minibatch, id2embeds, embedding_dim, mode = 'all'):\n",
    "    X, Y = minibatch\n",
    "    Y_prod = itertools.product(Y, repeat=3)\n",
    "    X_prod = itertools.product(X, repeat=3)\n",
    "    triplet = []\n",
    "    for x, y  in zip(X_prod, Y_prod):\n",
    "        xa, xp, xn = x\n",
    "        ya, yp, yn = y\n",
    "        if (ya == yp) and (ya!=yn) and (xa!=xp):\n",
    "            triplet.append((xa, xp, xn))\n",
    "    \n",
    "    num_triplets = len(triplet)\n",
    "    anchor = torch.zeros(num_triplets, embedding_dim)\n",
    "    positive = torch.zeros(num_triplets, embedding_dim)\n",
    "    negative = torch.zeros(num_triplets, embedding_dim)\n",
    "    for i in range(num_triplets):\n",
    "        xa, xp, xn = triplet[i]\n",
    "        anchor[i, :] = id2embeds[xa]\n",
    "        positive[i, :] = id2embeds[xp]\n",
    "        negative[i, :] = id2embeds[xn]\n",
    "        \n",
    "    return anchor, positive, negative\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, alpha = 0.2):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "            \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        alpha = self.alpha\n",
    "        pos_dist = anchor - positive\n",
    "        pos_dist = torch.pow(pos_dist, 2).sum(dim=0)\n",
    "        print(pos_dist, pos_dist.shape)\n",
    "        neg_dist = anchor - negative\n",
    "        neg_dist = torch.pow(neg_dist, 2).sum(dim=0)\n",
    "        print(neg_dist)\n",
    "        basic_loss = pos_dist - neg_dist + alpha\n",
    "    #     loss = torch.max(basic_loss, torch.zeros(basic_loss.shape[0])).sum()\n",
    "        loss = torch.clamp(basic_loss, min=0.0).sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data_dir, transform)\n",
    "data = dataloader.gen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alexnet(nn.Module):\n",
    "    def __init__(self, embedding_dim=32):\n",
    "        super(Alexnet, self).__init__()\n",
    "        self.alexnet = models.alexnet(pretrained=True)\n",
    "        in_features = self.alexnet.classifier[6].in_features\n",
    "        self.linear = nn.Linear(in_features, embedding_dim)\n",
    "        self.alexnet.classifier[6] = self.linear\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.linear.weight.data.normal_(0.0, 0.02)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "    \n",
    "    def forward(self, images):\n",
    "        embed = self.alexnet(images)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Alexnet(embedding_dim = embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = 0\n",
    "if torch.cuda.is_available():\n",
    "    with torch.cuda.device(gpu_device):\n",
    "        cnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-7\n",
    "params = cnn.parameters()\n",
    "optimizer = torch.optim.Adam(params, lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(anchor, positive, negative, alpha=0.2):\n",
    "    return TripletLoss(alpha)(anchor, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alexnet(\n",
       "  (alexnet): AlexNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace)\n",
       "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5)\n",
       "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Dropout(p=0.5)\n",
       "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): Linear(in_features=4096, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=4096, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]) torch.Size([32])\n",
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.4000)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_loss(anchor, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatches = make_minibatches(data, seed = epoch)\n",
    "loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_minibatch = minibatches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2embeds = batch2embeddings(cur_minibatch[0], cnn, dataloader, gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         ...,\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702]]),\n",
       " tensor([[-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         ...,\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702]]),\n",
       " tensor([[-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         ...,\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702],\n",
       "         [-0.7229, -0.7830,  0.5068,  ..., -2.1230, -1.3338, -1.0702]]))"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor, positive, negative = gen_triplets(cur_minibatch, id2embeds, embedding_dim)\n",
    "anchor, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]) torch.Size([32])\n",
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "l = triplet_loss(anchor, positive, negative)\n",
    "loss.append(l)\n",
    "l.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(54.7556)\n",
      "tensor(43.8222)\n",
      "tensor(53.5556)\n",
      "tensor(46.5333)\n",
      "tensor(47.2444)\n",
      "tensor(53.1556)\n",
      "tensor(44.9778)\n",
      "tensor(54.4444)\n",
      "tensor(55.1556)\n",
      "tensor(57.5556)\n",
      "tensor(53.2000)\n",
      "tensor(52.8889)\n",
      "tensor(51.1556)\n",
      "tensor(54.0889)\n",
      "tensor(45.7333)\n",
      "tensor(56.8889)\n",
      "tensor(48.7111)\n",
      "tensor(53.4667)\n",
      "tensor(48.4444)\n",
      "tensor(53.3333)\n",
      "tensor(51.8222)\n",
      "tensor(51.1111)\n",
      "tensor(50.)\n",
      "tensor(59.9556)\n",
      "tensor(53.1556)\n",
      "tensor(51.3778)\n",
      "tensor(59.9111)\n",
      "tensor(51.2444)\n",
      "tensor(53.5556)\n",
      "tensor(55.6889)\n",
      "tensor(49.7333)\n",
      "tensor(46.7111)\n",
      "tensor(45.7778)\n",
      "tensor(46.2667)\n",
      "tensor(50.3111)\n",
      "tensor(48.5333)\n",
      "tensor(47.5556)\n",
      "tensor(55.4222)\n",
      "tensor(58.9778)\n",
      "tensor(43.2444)\n",
      "tensor(52.9778)\n",
      "tensor(50.7111)\n",
      "tensor(46.0889)\n",
      "tensor(54.4889)\n",
      "tensor(49.3778)\n",
      "tensor(48.8889)\n",
      "tensor(55.6000)\n",
      "tensor(48.6222)\n",
      "tensor(50.8444)\n",
      "tensor(55.6000)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    minibatches = make_minibatches(data, seed = epoch)\n",
    "    loss = []\n",
    "    for cur_minibatch in minibatches:\n",
    "        id2embeds = batch2embeddings(cur_minibatch[0], cnn, dataloader, gpu_device)\n",
    "        anchor, positive, negative = gen_triplets(cur_minibatch, id2embeds, embedding_dim)\n",
    "        l = triplet_loss(anchor, positive, negative)\n",
    "        loss.append(l)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print(torch.mean(torch.Tensor(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = torch.randn((10, 128))\n",
    "embed = torch.randn(128)\n",
    "dis = torch.pow(embeds - embed, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = dis.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.argmin(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(a.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
